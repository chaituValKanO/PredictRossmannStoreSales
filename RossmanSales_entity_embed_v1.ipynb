{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chaitanyav/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['TF_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If Radam and LookAhead optimizers are not installed then uncomment the below lines\n",
    "\n",
    "# ! pip install keras-rectified-adam\n",
    "# ! pip install keras-lookahead\n",
    "# ! pip install mpld3\n",
    "# ! pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Reshape, Concatenate, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_radam\n",
    "# !pip install keras_lookahead\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras_lookahead import Lookahead\n",
    "from Mish import Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1243)\n",
    "\n",
    "np.random.seed(1243)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data - Rossmann Sales Forecasting\n",
    "\n",
    "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied\n",
    "\n",
    "Submissions are evaluated on the Root Mean Square Percentage Error (RMSPE). The RMSPE is calculated as\n",
    "\n",
    "<img src=\"images/rmspe.png\" />\n",
    "where y_i denotes the sales of a single store on a single day and yhat_i denotes the corresponding prediction. Any day and store with 0 sales is ignored in scoring.<br>\n",
    "\n",
    "https://www.kaggle.com/c/rossmann-store-sales/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving models to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models\n",
      "saving models to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/images\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "image_dir = os.path.join(os.getcwd(), 'images')\n",
    "print(f\"saving models to {save_dir}\")\n",
    "print(f\"saving models to {image_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\",parse_dates=[2], low_memory=False)\n",
    "test = pd.read_csv(\"data/test.csv\",parse_dates=[3], low_memory=False)\n",
    "store = pd.read_csv(\"data/store.csv\")\n",
    "store_states = pd.read_csv(\"data/store_states.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape is (1017209, 9)\n",
      "Test Data shape is (41088, 8)\n",
      "Store Data shape is (1115, 10)\n",
      "Store state data is (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape is {data.shape}\")\n",
    "print(f\"Test Data shape is {test.shape}\")\n",
    "print(f\"Store Data shape is {store.shape}\")\n",
    "print(f\"Store state data is {store_states.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5 2015-07-31   5263        555     1      1            0   \n",
       "1      2          5 2015-07-31   6064        625     1      1            0   \n",
       "2      3          5 2015-07-31   8314        821     1      1            0   \n",
       "3      4          5 2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5 2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data -> Null Values:\n",
      " Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64\n",
      "\n",
      "Store Data -> Null Values:\n",
      " Store                          0\n",
      "StoreType                      0\n",
      "Assortment                     0\n",
      "CompetitionDistance            3\n",
      "CompetitionOpenSinceMonth    354\n",
      "CompetitionOpenSinceYear     354\n",
      "Promo2                         0\n",
      "Promo2SinceWeek              544\n",
      "Promo2SinceYear              544\n",
      "PromoInterval                544\n",
      "dtype: int64\n",
      "\n",
      "Store State - > Null values:\n",
      "Store    0\n",
      "State    0\n",
      "dtype: int64\n",
      "\n",
      "Test Data -> Null Values:\n",
      " Id                0\n",
      "Store             0\n",
      "DayOfWeek         0\n",
      "Date              0\n",
      "Open             11\n",
      "Promo             0\n",
      "StateHoliday      0\n",
      "SchoolHoliday     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nData -> Null Values:\\n {data.isnull().sum()}\")\n",
    "print(f\"\\nStore Data -> Null Values:\\n {store.isnull().sum()}\")\n",
    "print(f\"\\nStore State - > Null values:\\n{store_states.isnull().sum()}\")\n",
    "print(f\"\\nTest Data -> Null Values:\\n {test.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the store should be open in the test,so we fill na with 1\n",
    "test.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna in store with 0\n",
    "store.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store State\n",
       "0      1    HE\n",
       "1      2    TH\n",
       "2      3    NW\n",
       "3      4    BE\n",
       "4      5    SN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging of stores state and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data after merging is\n",
      " (1017209, 10)\n",
      "The store shape after merge is (1115, 11)\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.merge(store, store_states[['Store', 'State']], on='Store')\n",
    "data = pd.merge(data, store_states[['Store', 'State']], on='Store')\n",
    "\n",
    "print(f\"The data after merging is\\n {data.shape}\")\n",
    "print(f\"The store shape after merge is {store_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Open\"] != 0]\n",
    "data = data[data[\"Sales\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['Date'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data, isTrain):\n",
    "  data['Year'] = data.Date.dt.year\n",
    "  data['Month'] = data.Date.dt.month\n",
    "  data['Day'] = data.Date.dt.day\n",
    "  data['DayOfWeek'] = data['DayOfWeek'].astype('int64')\n",
    "#   data['AdjStore'] = store_data[data['Store'] - 1]['State']\n",
    "  if isTrain:\n",
    "    data['Sales'] = data['Sales'].astype('float64')\n",
    "    return data[['Open', 'Store', 'DayOfWeek', 'Promo', 'Year', 'Month', 'Day', 'State', \"Sales\"]]\n",
    "  else:\n",
    "    return data[['Open', 'Store', 'DayOfWeek', 'Promo', 'Year', 'Month', 'Day', 'State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844338,)\n"
     ]
    }
   ],
   "source": [
    "train_data = create_features(data, isTrain=True)\n",
    "train_data_X = train_data.drop(['Sales'],axis=1 )\n",
    "train_data_y = train_data['Sales']\n",
    "print(train_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "les = []\n",
    "for i in range(train_data_X.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data_X.iloc[:, i])\n",
    "    les.append(le)\n",
    "    train_data_X.iloc[:, i] = le.transform(train_data_X.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844338, 8)\n",
      "(844338,)\n"
     ]
    }
   ],
   "source": [
    "train_data_X = train_data_X.astype(int)\n",
    "train_data_y = np.array(train_data_y)\n",
    "\n",
    "print(train_data_X.shape)\n",
    "print(train_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the last 6 weeks data as validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As data is sorted and there are 1115 stores in total, we will need to multiply by 6 (weeks) * 7(days in week) * 1115(noofstores)\n",
    "X_val = train_data_X[:6*7*1115]\n",
    "X_train = train_data_X[6*7*1115:]\n",
    "\n",
    "y_val = train_data_y[:6*7*1115]\n",
    "y_train = train_data_y[6*7*1115:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape is (797508, 8)\n",
      "validation Data shape is (46830, 8)\n",
      "Train Data shape is (797508,)\n",
      "validation Data shape is (46830,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data shape is {X_train.shape}\")\n",
    "print(f\"validation Data shape is {X_val.shape}\")\n",
    "\n",
    "print(f\"Train Data shape is {y_train.shape}\")\n",
    "print(f\"validation Data shape is {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Promo</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146142</th>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143500</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709530</th>\n",
       "      <td>0</td>\n",
       "      <td>779</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144258</th>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open  Store  DayOfWeek  Promo  Year  Month  Day  State\n",
       "0          0      0          4      1     2      6   30      4\n",
       "146142     0    161          4      1     2      6   30      4\n",
       "143500     0    158          4      1     2      6   30      2\n",
       "709530     0    779          4      1     2      6   30      9\n",
       "144258     0    159          4      1     2      6   30      4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features(X):\n",
    "    X_list = []\n",
    "\n",
    "    store_index = X.iloc[:, 1]\n",
    "    X_list.append(store_index)\n",
    "\n",
    "    day_of_week = X.iloc[:, 2]\n",
    "    X_list.append(day_of_week)\n",
    "\n",
    "    promo = X.iloc[:, 3]\n",
    "    X_list.append(promo)\n",
    "\n",
    "    year = X.iloc[:, 4]\n",
    "    X_list.append(year)\n",
    "\n",
    "    month = X.iloc[:, 5]\n",
    "    X_list.append(month)\n",
    "\n",
    "    day = X.iloc[:, 6]\n",
    "    X_list.append(day)\n",
    "\n",
    "    State = X.iloc[:, 7]\n",
    "    X_list.append(State)\n",
    "\n",
    "    return X_list\n",
    "\n",
    "def val_for_fit(val, max_log_y):\n",
    "  val = np.log(val) / max_log_y\n",
    "  return val\n",
    "\n",
    "def val_for_pred(val, max_log_y):\n",
    "  return np.exp(val * max_log_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(save_dir, \"best_model_weights_EE.h5\"), \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, mode='min', verbose=1)\n",
    "\n",
    "max_log_y = max(np.max(np.log(y_train)), np.max(np.log(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = split_features(X_train)\n",
    "X_val_list = split_features(X_val)\n",
    "\n",
    "y_train_trans = val_for_fit(y_train, max_log_y)\n",
    "y_val_trans = val_for_fit(y_val, max_log_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_embed_model():\n",
    "  \n",
    "  input_store = Input(shape=(1,))\n",
    "  output_store = Embedding(1115, 10, name='store_embedding')(input_store)\n",
    "  output_store = Reshape(target_shape=(10,))(output_store)\n",
    "\n",
    "  input_dow = Input(shape=(1,))\n",
    "  output_dow = Embedding(7, 6, name='dow_embedding')(input_dow)\n",
    "  output_dow = Reshape(target_shape=(6,))(output_dow)\n",
    "\n",
    "  input_promo = Input(shape=(1,))\n",
    "  output_promo = Dense(1)(input_promo)\n",
    "\n",
    "  input_year = Input(shape=(1,))\n",
    "  output_year = Embedding(3, 2, name='year_embedding')(input_year)\n",
    "  output_year = Reshape(target_shape=(2,))(output_year)\n",
    "\n",
    "  input_month = Input(shape=(1,))\n",
    "  output_month = Embedding(12, 6, name='month_embedding')(input_month)\n",
    "  output_month = Reshape(target_shape=(6,))(output_month)\n",
    "\n",
    "  input_day = Input(shape=(1,))\n",
    "  output_day = Embedding(31, 10, name='day_embedding')(input_day)\n",
    "  output_day = Reshape(target_shape=(10,))(output_day)\n",
    "\n",
    "  input_germanstate = Input(shape=(1,))\n",
    "  output_germanstate = Embedding(12, 6, name='state_embedding')(input_germanstate)\n",
    "  output_germanstate = Reshape(target_shape=(6,))(output_germanstate)\n",
    "\n",
    "  input_model = [input_store, input_dow, input_promo,\n",
    "                 input_year, input_month, input_day, input_germanstate]\n",
    "\n",
    "  output_embeddings = [output_store, output_dow, output_promo,\n",
    "                       output_year, output_month, output_day, output_germanstate]\n",
    "\n",
    "  output_model = Concatenate()(output_embeddings)\n",
    "  output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
    "  output_model = Activation('relu')(output_model)\n",
    "  output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
    "  output_model = Activation('relu')(output_model)\n",
    "  output_model = Dense(1)(output_model)\n",
    "  output_model = Activation('sigmoid')(output_model)\n",
    "\n",
    "  model = Model(inputs=input_model, outputs=output_model)\n",
    "\n",
    "  model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_entity_embed_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 797508 samples, validate on 46830 samples\n",
      "Epoch 1/100\n",
      "797312/797508 [============================>.] - ETA: 0s - loss: 0.0101\n",
      "Epoch 00001: val_loss improved from inf to 0.00956, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 32s 40us/sample - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 2/100\n",
      "797184/797508 [============================>.] - ETA: 0s - loss: 0.0075\n",
      "Epoch 00002: val_loss improved from 0.00956 to 0.00888, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 3/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00003: val_loss improved from 0.00888 to 0.00862, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 4/100\n",
      "796544/797508 [============================>.] - ETA: 0s - loss: 0.0068\n",
      "Epoch 00004: val_loss improved from 0.00862 to 0.00856, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 5/100\n",
      "797184/797508 [============================>.] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00005: val_loss improved from 0.00856 to 0.00845, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 6/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00006: val_loss improved from 0.00845 to 0.00839, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 7/100\n",
      "796928/797508 [============================>.] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00007: val_loss did not improve from 0.00839\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 8/100\n",
      "797056/797508 [============================>.] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00008: val_loss improved from 0.00839 to 0.00838, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 9/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00009: val_loss did not improve from 0.00838\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 10/100\n",
      "797056/797508 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00010: val_loss improved from 0.00838 to 0.00836, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 11/100\n",
      "796672/797508 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00011: val_loss did not improve from 0.00836\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0062 - val_loss: 0.0087\n",
      "Epoch 12/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00012: val_loss did not improve from 0.00836\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0062 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "796160/797508 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00013: val_loss did not improve from 0.00836\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 14/100\n",
      "796160/797508 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00014: val_loss did not improve from 0.00836\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 15/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00015: val_loss did not improve from 0.00836\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 16/100\n",
      "797312/797508 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00016: val_loss improved from 0.00836 to 0.00831, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 17/100\n",
      "797056/797508 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00017: val_loss did not improve from 0.00831\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 18/100\n",
      "797184/797508 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00018: val_loss improved from 0.00831 to 0.00827, saving model to /nfsroot/data/home/chaitanyav/AIB/Supervised/StructuredData/Rossmann-store-sales/saved_models/best_model_weights_EE.h5\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 19/100\n",
      "796672/797508 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00019: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 20/100\n",
      "797056/797508 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00020: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 21/100\n",
      "796800/797508 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00021: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "796160/797508 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00022: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 23/100\n",
      "796672/797508 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00023: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 24/100\n",
      "796928/797508 [============================>.] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00024: val_loss did not improve from 0.00827\n",
      "797508/797508 [==============================] - 31s 39us/sample - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff59e7d0a20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_list, y_train_trans,\n",
    "                       validation_data=(X_val_list, y_val_trans),\n",
    "                       epochs=epochs, batch_size=128,\n",
    "                       callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_struc_data = load_model(os.path.join(save_dir, 'best_model_weights_EE.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = val_for_pred(model_struc_data.predict(X_train_list).flatten(), max_log_y)\n",
    "yhat_val = val_for_pred(model_struc_data.predict(X_val_list).flatten(), max_log_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7824.6294,  2713.6548,  8444.142 , ...,  5447.224 , 17003.213 ,\n",
       "        7845.7383], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean(np.square(1-(yhat/y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE error on train data = 0.1779705414260236\n",
      "RMSPE error on validation data = 0.1219273350371198\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSPE error on train data = {rmspe(y_train, yhat_train)}\")\n",
    "print(f\"RMSPE error on validation data = {rmspe(y_val, yhat_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1713</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3425</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0     1      1          4 2015-09-17   1.0      1            0              0   \n",
       "1   857      1          3 2015-09-16   1.0      1            0              0   \n",
       "2  1713      1          2 2015-09-15   1.0      1            0              0   \n",
       "3  2569      1          1 2015-09-14   1.0      1            0              0   \n",
       "4  3425      1          7 2015-09-13   1.0      0            0              0   \n",
       "\n",
       "  State  \n",
       "0    HE  \n",
       "1    HE  \n",
       "2    HE  \n",
       "3    HE  \n",
       "4    HE  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(test, store_states[['Store', 'State']], on='Store')\n",
    "\n",
    "test[\"Open\"] = test[\"Open\"].replace([0], [1])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testID = test['Id']\n",
    "test = test.drop(['Id'], axis=1)\n",
    "\n",
    "test = create_features(test, False)\n",
    "\n",
    "for i in range(len(les)):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data_X.iloc[:, i])\n",
    "    le = les[i]\n",
    "    test.iloc[:, i] = le.transform(test.iloc[:, i])\n",
    "\n",
    "test = test.astype(int)\n",
    "\n",
    "test = split_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = val_for_pred(model_struc_data.predict(test).flatten(), max_log_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Id': testID, 'Sales': yhat_test})\n",
    "result.to_csv(\"Rossmann_submission_EE.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
