{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rossmann Store Sales - Forecast sales using store, promotion, and competitor data\n",
    "\n",
    "    Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Data\n",
    "\n",
    "    1) train.csv - historical data including Sales <br>\n",
    "    2) store_states.csv - State where the store is located in Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Input, Dense, Activation, concatenate, Flatten, Reshape, Concatenate\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeevan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\", sep=',',header=0)\n",
    "state_data = pd.read_csv(\"store_states.csv\", sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data - Shape \n",
      "(1017209, 9)\n",
      "\n",
      "Store States Data - Shape \n",
      "(1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain Data - Shape \\n{train_data.shape}\")\n",
    "print(f\"\\nStore States Data - Shape \\n{state_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "\n",
      "Train Data - Top 5 Records\n",
      "\n",
      "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
      "0      1          5  2015-07-31   5263        555     1      1            0   \n",
      "1      2          5  2015-07-31   6064        625     1      1            0   \n",
      "2      3          5  2015-07-31   8314        821     1      1            0   \n",
      "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
      "4      5          5  2015-07-31   4822        559     1      1            0   \n",
      "\n",
      "   SchoolHoliday  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Stores States Data - Top 5 Records\n",
      "\n",
      "   Store State\n",
      "0      1    HE\n",
      "1      2    TH\n",
      "2      3    NW\n",
      "3      4    BE\n",
      "4      5    SN\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------------\\n\")\n",
    "print(f\"Train Data - Top 5 Records\\n\\n{train_data.head()}\\n\")\n",
    "print(\"---------------------------------------------------------------------\\n\")\n",
    "print(f\"\\nStores States Data - Top 5 Records\\n\\n{state_data.head()}\\n\")\n",
    "print(\"---------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "    a) Store is a common attribute in both the datasets which can be used to merge datasets.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_data['Store']).size)\n",
    "print(np.unique(state_data['Store']).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data - Summary \n",
      "\n",
      "               Store     DayOfWeek        Date         Sales     Customers  \\\n",
      "count   1.017209e+06  1.017209e+06     1017209  1.017209e+06  1.017209e+06   \n",
      "unique           NaN           NaN         942           NaN           NaN   \n",
      "top              NaN           NaN  2013-06-17           NaN           NaN   \n",
      "freq             NaN           NaN        1115           NaN           NaN   \n",
      "mean    5.584297e+02  3.998341e+00         NaN  5.773819e+03  6.331459e+02   \n",
      "std     3.219087e+02  1.997391e+00         NaN  3.849926e+03  4.644117e+02   \n",
      "min     1.000000e+00  1.000000e+00         NaN  0.000000e+00  0.000000e+00   \n",
      "25%     2.800000e+02  2.000000e+00         NaN  3.727000e+03  4.050000e+02   \n",
      "50%     5.580000e+02  4.000000e+00         NaN  5.744000e+03  6.090000e+02   \n",
      "75%     8.380000e+02  6.000000e+00         NaN  7.856000e+03  8.370000e+02   \n",
      "max     1.115000e+03  7.000000e+00         NaN  4.155100e+04  7.388000e+03   \n",
      "\n",
      "                Open         Promo StateHoliday  SchoolHoliday  \n",
      "count   1.017209e+06  1.017209e+06      1017209   1.017209e+06  \n",
      "unique           NaN           NaN            5            NaN  \n",
      "top              NaN           NaN            0            NaN  \n",
      "freq             NaN           NaN       855087            NaN  \n",
      "mean    8.301067e-01  3.815145e-01          NaN   1.786467e-01  \n",
      "std     3.755392e-01  4.857586e-01          NaN   3.830564e-01  \n",
      "min     0.000000e+00  0.000000e+00          NaN   0.000000e+00  \n",
      "25%     1.000000e+00  0.000000e+00          NaN   0.000000e+00  \n",
      "50%     1.000000e+00  0.000000e+00          NaN   0.000000e+00  \n",
      "75%     1.000000e+00  1.000000e+00          NaN   0.000000e+00  \n",
      "max     1.000000e+00  1.000000e+00          NaN   1.000000e+00  \n",
      "\n",
      "\n",
      "Store States Data - Summary \n",
      "\n",
      "             Store State\n",
      "count   1115.00000  1115\n",
      "unique         NaN    12\n",
      "top            NaN    NW\n",
      "freq           NaN   286\n",
      "mean     558.00000   NaN\n",
      "std      322.01708   NaN\n",
      "min        1.00000   NaN\n",
      "25%      279.50000   NaN\n",
      "50%      558.00000   NaN\n",
      "75%      836.50000   NaN\n",
      "max     1115.00000   NaN\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain Data - Summary \\n\\n{train_data.describe(include = 'all')}\")\n",
    "print(f\"\\n\\nStore States Data - Summary \\n\\n{state_data.describe(include = 'all')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data - Data Types \n",
      "Store             int64\n",
      "DayOfWeek         int64\n",
      "Date             object\n",
      "Sales             int64\n",
      "Customers         int64\n",
      "Open              int64\n",
      "Promo             int64\n",
      "StateHoliday     object\n",
      "SchoolHoliday     int64\n",
      "dtype: object\n",
      "\n",
      "Store States Data - Data Types \n",
      "Store     int64\n",
      "State    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Data - Data Types \\n{}\".format(train_data.dtypes))\n",
    "print(\"\\nStore States Data - Data Types \\n{}\".format(state_data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Date attribute in to appropriate type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Date'] = pd.to_datetime(train_data['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "\n",
    "    Finding missing values in train, state, and stores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data - Missing values \n",
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64\n",
      "\n",
      "Store States Data - Missing value \n",
      "Store    0\n",
      "State    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain Data - Missing values \\n{train_data.isnull().sum()}\")\n",
    "print(f\"\\nStore States Data - Missing value \\n{state_data.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Date Month and Year from the Date attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['year'] = train_data['Date'].dt.year\n",
    "train_data['month'] = train_data['Date'].dt.month\n",
    "train_data['day'] = train_data['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5 2015-07-31   5263        555     1      1            0   \n",
       "1      2          5 2015-07-31   6064        625     1      1            0   \n",
       "2      3          5 2015-07-31   8314        821     1      1            0   \n",
       "3      4          5 2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5 2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  year  month  day  \n",
       "0              1  2015      7   31  \n",
       "1              1  2015      7   31  \n",
       "2              1  2015      7   31  \n",
       "3              1  2015      7   31  \n",
       "4              1  2015      7   31  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Rows with zero Sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017209, 12)\n",
      "(844338, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data = train_data[train_data['Sales']!=0]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Train Data with State Data\n",
    "\n",
    "    Performing inner join on Store attribute between train_data and state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_data['Store']).size)\n",
    "print(np.unique(state_data['Store']).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, state_data, on='Store', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>5020</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>4782</td>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>5011</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>6102</td>\n",
       "      <td>612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5 2015-07-31   5263        555     1      1            0   \n",
       "1      1          4 2015-07-30   5020        546     1      1            0   \n",
       "2      1          3 2015-07-29   4782        523     1      1            0   \n",
       "3      1          2 2015-07-28   5011        560     1      1            0   \n",
       "4      1          1 2015-07-27   6102        612     1      1            0   \n",
       "\n",
       "   SchoolHoliday  year  month  day State  \n",
       "0              1  2015      7   31    HE  \n",
       "1              1  2015      7   30    HE  \n",
       "2              1  2015      7   29    HE  \n",
       "3              1  2015      7   28    HE  \n",
       "4              1  2015      7   27    HE  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844338, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting only required columns for model building\n",
    "\n",
    "    Only {'Store','DayOfWeek','Promo','year', 'month', 'day', 'State'} attributes effect sales attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = train_data[['Store','DayOfWeek','Promo','year', 'month', 'day', 'State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y = train_data['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_data_X is (844338, 7)\n",
      "The shape of train_data_y is (844338,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of train_data_X is {train_data_X.shape}\")\n",
    "print(f\"The shape of train_data_y is {train_data_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store has : 1115 unique values\n",
      "DayOfWeek has : 7 unique values\n",
      "Promo has : 2 unique values\n",
      "year has : 3 unique values\n",
      "month has : 12 unique values\n",
      "day has : 31 unique values\n",
      "State has : 12 unique values\n"
     ]
    }
   ],
   "source": [
    "for i in ['Store', 'DayOfWeek', 'Promo', 'year', 'month', 'day', 'State']:\n",
    "    print(\"{} has : {} unique values\".format(i, np.size(np.unique(train_data_X[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store         int64\n",
       "DayOfWeek     int64\n",
       "Promo         int64\n",
       "year          int64\n",
       "month         int64\n",
       "day           int64\n",
       "State        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert attributes in appropriate type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeevan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for col in ['Store', 'DayOfWeek', 'Promo', 'year', 'month', 'day', 'State']:\n",
    "    train_data_X[col] = train_data_X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store        category\n",
       "DayOfWeek    category\n",
       "Promo        category\n",
       "year         category\n",
       "month        category\n",
       "day          category\n",
       "State        category\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Custom Function for Preprocessing and to calculate Error Metrics (Mean Absolute Error)\n",
    "\n",
    "    As Sales in the data set spans 4 orders of magnitude, we used log(Sale) and rescaled it to the same range as the neural network output with log(Sale)/log(Salemax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.634676867382668"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_log_y = np.max(np.log(train_data_y))\n",
    "max_log_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below cell is for explanation purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sales values              :5263\n",
      "Log of Actual Sales values       :8.56845648535378\n",
      "Transformed Sales values         :0.8057091524457939\n",
      "Inverse Transformed Sales values :5263.000000000004\n"
     ]
    }
   ],
   "source": [
    "temp = train_data_y[:1][0]\n",
    "log_temp = np.log(temp)\n",
    "tran_temp = log_temp/max_log_y\n",
    "inv_tran_temp = tran_temp * max_log_y\n",
    "org_temp = np.exp(inv_tran_temp)\n",
    "\n",
    "print(\"Actual Sales values              :{}\".format(temp))\n",
    "print(\"Log of Actual Sales values       :{}\".format(log_temp))\n",
    "print(\"Transformed Sales values         :{}\".format(tran_temp))\n",
    "print(\"Inverse Transformed Sales values :{}\".format(org_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the sales by dividing with maximum of sales. Default base of log function is e.\n",
    "def val_for_fit(val):\n",
    "    val = np.log(val)/max_log_y\n",
    "    return val\n",
    "\n",
    "# Denormalizing the predicted values back to original scale by multiplying with max and taking exponential\n",
    "def val_for_pred(val):\n",
    "    return np.exp(val * max_log_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Label Encoder for all Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Promo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Store DayOfWeek Promo  year month day State\n",
       "0     1         5     1  2015     7  31    HE\n",
       "1     1         4     1  2015     7  30    HE\n",
       "2     1         3     1  2015     7  29    HE\n",
       "3     1         2     1  2015     7  28    HE\n",
       "4     1         1     1  2015     7  27    HE"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X_LE = train_data_X.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Promo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek  Promo  year  month  day  State\n",
       "0      0          4      1     2      6   30      4\n",
       "1      0          3      1     2      6   29      4\n",
       "2      0          2      1     2      6   28      4\n",
       "3      0          1      1     2      6   27      4\n",
       "4      0          0      1     2      6   26      4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_LE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_X_OHE = enc.fit_transform(train_data_X_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X_OHE = enc.transform(train_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844338, 1182)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_OHE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CE, X_val_CE, X_train_OHE, X_val_OHE, y_train, y_val = train_test_split(train_data_X_LE.values, \n",
    "                                                                                train_data_X_OHE, \n",
    "                                                                                train_data_y.values, \n",
    "                                                                                test_size=0.1, \n",
    "                                                                                random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_CE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeevan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(1000, kernel_initializer=\"uniform\", input_dim=1182, activation='relu'))\n",
    "model1.add(Dense(500, kernel_initializer=\"uniform\", activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the sales (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jeevan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 759904 samples, validate on 84434 samples\n",
      "Epoch 1/100\n",
      "759904/759904 [==============================] - 162s 214us/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "759904/759904 [==============================] - 161s 212us/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 3/100\n",
      "759904/759904 [==============================] - 159s 209us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 5/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 6/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 7/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 8/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 9/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 10/100\n",
      "759904/759904 [==============================] - 157s 207us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 11/100\n",
      "759904/759904 [==============================] - 157s 206us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 12/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 13/100\n",
      "759904/759904 [==============================] - 151s 199us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 14/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 16/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 17/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 18/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 19/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0037 - val_loss: 0.0068\n",
      "Epoch 20/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 21/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 22/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 23/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0034 - val_loss: 0.0069\n",
      "Epoch 24/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0033 - val_loss: 0.0069\n",
      "Epoch 25/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0033 - val_loss: 0.0069\n",
      "Epoch 26/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0032 - val_loss: 0.0070\n",
      "Epoch 27/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 28/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0031 - val_loss: 0.0069\n",
      "Epoch 29/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 30/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 31/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 32/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0029 - val_loss: 0.0070\n",
      "Epoch 33/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0029 - val_loss: 0.0070\n",
      "Epoch 34/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0029 - val_loss: 0.0071\n",
      "Epoch 35/100\n",
      "759904/759904 [==============================] - 151s 198us/step - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 36/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 37/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 38/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 39/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 40/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 41/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Epoch 42/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 43/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 44/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 45/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 46/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 47/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 48/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 49/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 50/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 51/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 52/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 53/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 54/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 55/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 56/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 57/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 58/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 59/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 60/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 61/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 62/100\n",
      "759904/759904 [==============================] - 149s 197us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 63/100\n",
      "759904/759904 [==============================] - 150s 197us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 64/100\n",
      "759904/759904 [==============================] - 152s 200us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "759904/759904 [==============================] - 165s 217us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 66/100\n",
      "759904/759904 [==============================] - 165s 217us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 67/100\n",
      "759904/759904 [==============================] - 165s 217us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 68/100\n",
      "759904/759904 [==============================] - 160s 211us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 69/100\n",
      "759904/759904 [==============================] - 160s 211us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 70/100\n",
      "759904/759904 [==============================] - 154s 202us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 71/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 73/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 74/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 75/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 76/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 77/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 78/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "759904/759904 [==============================] - 148s 194us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 80/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 81/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 82/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 83/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 84/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 85/100\n",
      "759904/759904 [==============================] - 148s 194us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 86/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 87/100\n",
      "759904/759904 [==============================] - 148s 194us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 88/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 89/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 90/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 91/100\n",
      "759904/759904 [==============================] - 163s 215us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 92/100\n",
      "759904/759904 [==============================] - 160s 210us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 93/100\n",
      "759904/759904 [==============================] - 153s 201us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 94/100\n",
      "759904/759904 [==============================] - 156s 205us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 95/100\n",
      "759904/759904 [==============================] - 152s 200us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 96/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 97/100\n",
      "759904/759904 [==============================] - 153s 201us/step - loss: 0.0018 - val_loss: 0.0076\n",
      "Epoch 98/100\n",
      "759904/759904 [==============================] - 150s 198us/step - loss: 0.0018 - val_loss: 0.0076\n",
      "Epoch 99/100\n",
      "759904/759904 [==============================] - 149s 196us/step - loss: 0.0018 - val_loss: 0.0076\n",
      "Epoch 100/100\n",
      "759904/759904 [==============================] - 148s 195us/step - loss: 0.0018 - val_loss: 0.0076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76304d3da0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_OHE, val_for_fit(y_train), \n",
    "           validation_data=(X_val_OHE, val_for_fit(y_val)),\n",
    "           epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7890064 , 0.8167372 , 0.78986704, ..., 0.8541412 , 0.85121775,\n",
       "       0.8225953 ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model1.predict(X_val_OHE).flatten()\n",
    "y_pred_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4406.4653, 5917.8926, 4446.9805, ..., 8808.876 , 8539.224 ,\n",
       "       6298.3027], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = val_for_pred(y_pred_val)\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.250517950999635"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_val_err = (np.sum(np.absolute((y_val - y_pred_val) / y_val))/len(y_val)) * 100\n",
    "model1_val_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data for MLP with Categorial embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caregorical Embeddings\n",
    "    \n",
    "    We map categorical variables to a Euclidean spaces, which are the entity embeddings of the categorical variables.  The mapping is learned by a neural network during the standard supervised training process.  Entity embedding not only reduces memory usage and speeds up neural networks compared with one-hot encoding, but more importantly by mapping similar values close to each other in the embedding space it reveals the intrinsic properties of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X):\n",
    "    X_list = split_features(X)\n",
    "    return X_list\n",
    "\n",
    "def split_features(X):\n",
    "    X_list = []\n",
    "\n",
    "    store_index = X[..., [0]]\n",
    "    X_list.append(store_index)\n",
    "\n",
    "    day_of_week = X[..., [1]]\n",
    "    X_list.append(day_of_week)\n",
    "\n",
    "    promo = X[..., [2]]\n",
    "    X_list.append(promo)\n",
    "\n",
    "    year = X[..., [3]]\n",
    "    X_list.append(year)\n",
    "\n",
    "    month = X[..., [4]]\n",
    "    X_list.append(month)\n",
    "\n",
    "    day = X[..., [5]]\n",
    "    X_list.append(day)\n",
    "\n",
    "    State = X[..., [6]]\n",
    "    X_list.append(State)\n",
    "\n",
    "    return X_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding specific Embedding layer to each Categorical Variable\n",
    "\n",
    "As mentioned above we map categorical variables to Eucledian space there by mapping similar values close to each other in the embedding space. <br>\n",
    "\n",
    "This is achieved by adding a specific Embedding layer to each categorical attribute in the dataset. The EE mapping for each layer is inspired from a research paper published on Categorical Embeddings https://arxiv.org/pdf/1604.06737.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_store = Input(shape=(1,))\n",
    "output_store = Embedding(1115, 10, name='store_embedding')(input_store)\n",
    "output_store = Reshape(target_shape=(10,))(output_store)\n",
    "\n",
    "input_dow = Input(shape=(1,))\n",
    "output_dow = Embedding(7, 6, name='dow_embedding')(input_dow)\n",
    "output_dow = Reshape(target_shape=(6,))(output_dow)\n",
    "\n",
    "input_promo = Input(shape=(1,))\n",
    "\n",
    "input_year = Input(shape=(1,))\n",
    "output_year = Embedding(3, 2, name='year_embedding')(input_year)\n",
    "output_year = Reshape(target_shape=(2,))(output_year)\n",
    "\n",
    "input_month = Input(shape=(1,))\n",
    "output_month = Embedding(12, 6, name='month_embedding')(input_month)\n",
    "output_month = Reshape(target_shape=(6,))(output_month)\n",
    "\n",
    "input_day = Input(shape=(1,))\n",
    "output_day = Embedding(31, 10, name='day_embedding')(input_day)\n",
    "output_day = Reshape(target_shape=(10,))(output_day)\n",
    "\n",
    "input_germanstate = Input(shape=(1,))\n",
    "output_germanstate = Embedding(12, 6, name='state_embedding')(input_germanstate)\n",
    "output_germanstate = Reshape(target_shape=(6,))(output_germanstate)\n",
    "\n",
    "output_embeddings = [output_store, output_dow, input_promo,\n",
    "                     output_year, output_month, output_day, output_germanstate]\n",
    "\n",
    "output_model = Concatenate()(output_embeddings)\n",
    "output_model = Dense(1000, kernel_initializer=\"uniform\", activation='relu')(output_model)\n",
    "output_model = Dense(500, kernel_initializer=\"uniform\", activation='relu')(output_model)\n",
    "output_model = Dense(1, activation='sigmoid')(output_model)\n",
    "\n",
    "input_model = [input_store, input_dow, input_promo,\n",
    "               input_year, input_month, input_day, input_germanstate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=input_model, outputs=output_model)\n",
    "model2.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the Sales(target) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 759904 samples, validate on 84434 samples\n",
      "Epoch 1/100\n",
      "759904/759904 [==============================] - 59s 78us/step - loss: 0.0102 - val_loss: 0.0079\n",
      "Epoch 2/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 3/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 4/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 5/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 6/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 7/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 9/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 10/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 11/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 13/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 14/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 15/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 16/100\n",
      "759904/759904 [==============================] - 61s 81us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "759904/759904 [==============================] - 59s 78us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 18/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "759904/759904 [==============================] - 61s 80us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "759904/759904 [==============================] - 60s 79us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 21/100\n",
      "759904/759904 [==============================] - 60s 78us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 22/100\n",
      "759904/759904 [==============================] - 60s 79us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 23/100\n",
      "759904/759904 [==============================] - 59s 78us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 24/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 25/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 26/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 27/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 28/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 29/100\n",
      "759904/759904 [==============================] - 57s 76us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 30/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 31/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 32/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 33/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 34/100\n",
      "759904/759904 [==============================] - 59s 77us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 35/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 36/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 37/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 38/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 40/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 41/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 42/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 43/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 44/100\n",
      "759904/759904 [==============================] - 57s 75us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 45/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 46/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 47/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 48/100\n",
      "759904/759904 [==============================] - 59s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 49/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 50/100\n",
      "759904/759904 [==============================] - 60s 79us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 51/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 52/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 53/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "759904/759904 [==============================] - 58s 77us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 55/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 56/100\n",
      "759904/759904 [==============================] - 61s 81us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 57/100\n",
      "759904/759904 [==============================] - 68s 89us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 58/100\n",
      "759904/759904 [==============================] - 65s 86us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 59/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 60/100\n",
      "759904/759904 [==============================] - 58s 76us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 61/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 62/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 63/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 64/100\n",
      "759904/759904 [==============================] - 67s 88us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 65/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 66/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 67/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 68/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 69/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 70/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 71/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 72/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 73/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 74/100\n",
      "759904/759904 [==============================] - 66s 87us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 76/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 77/100\n",
      "759904/759904 [==============================] - 62s 81us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 78/100\n",
      "759904/759904 [==============================] - 62s 81us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 79/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 80/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 81/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 82/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 83/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 84/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 85/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 86/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 87/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 88/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 89/100\n",
      "759904/759904 [==============================] - 63s 82us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 90/100\n",
      "759904/759904 [==============================] - 63s 82us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 91/100\n",
      "759904/759904 [==============================] - 63s 82us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 92/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 93/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 94/100\n",
      "759904/759904 [==============================] - 63s 82us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 95/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 96/100\n",
      "759904/759904 [==============================] - 62s 82us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 97/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 98/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 99/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 100/100\n",
      "759904/759904 [==============================] - 63s 83us/step - loss: 0.0054 - val_loss: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76186bda58>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(preprocessing(X_train_CE), val_for_fit(y_train), \n",
    "           validation_data=(preprocessing(X_val_CE), val_for_fit(y_val)), \n",
    "           epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_X_val = preprocessing(X_val_CE)\n",
    "\n",
    "y_pred_val = model2.predict(preproc_X_val).flatten()\n",
    "\n",
    "y_pred_val = val_for_pred(y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.277885322301708"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_val_err = (np.sum(np.absolute((y_val - y_pred_val) / y_val))/len(y_val))*100\n",
    "model2_val_err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
